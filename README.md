# ğŸ› ï¸ Data Engineering Prep for Big Tech

This repository documents my journey to becoming a Data Engineer at a top tech company (FAANG-level). It includes hands-on projects, technical exercises, and personal notes to strengthen core data engineering skillsâ€”covering everything from scalable pipelines and cloud data workflows to system design, SQL, and DSA prep.

---

## ğŸ“Œ Goals

- ğŸ§  Master LeetCode for algorithmic thinking (Neetcode, Leetcode)
- ğŸ—ï¸ Build robust ETL/ELT pipelines 
- ğŸ§® Practice SQL and dimensional data modeling  (Neetcode, DataExpert)
- ğŸ”„ Integrate batch and real-time processing  
- ğŸ¤– Automate workflows with orchestration tools  
- ğŸ“Š Create impactful data visualizations and dashboards  (PowerBi, Tableau, Looker. Streamlit)
- ğŸ§± Prepare for system design interviews  

---

## ğŸ§° Tech Stack

| Area                   | Tools & Technologies                              |
|------------------------|---------------------------------------------------|
| Programming            | Python, SQL                                       |
| Orchestration          | Apache Airflow, Prefect                           |
| Batch Processing       | Pandas, PySpark                                   |
| Streaming              | Kafka, Azure Event Hub                            |
| Cloud Platforms        | Azure, AWS, GCP                                   |
| Data Warehousing       | BigQuery, Snowflake, Azure Synapse                |
| Visualization & BI     | Power BI, Looker, Streamlit                       |
| CI/CD & Automation     | GitHub Actions, dbt                               |
| Data Storage           | Amazon S3, Azure, GCS                             |

---

## ğŸ“ˆ Key Projects & Features

- **Batch Pipelines**: Ingest and transform data (CSV/JSON) into cloud warehouses using Data Factory, AWS Glue and custom ETL scripts  
- **Streaming Pipelines**: Real-time ingestion with Kafka/Event Hub and processing with Spark Structured Streaming  
- **Data Modeling**: Star schema and normalized models for analytics  
- **Dashboards**: Interactive reporting using Power BI and Streamlit  
- **Automation**: Workflow orchestration using Airflow DAGs  
- **Testing**: Unit tests and data quality checks on transformations  

---

## ğŸ§­ About This Project

Iâ€™m **Selenge**â€”a Data Engineer on a focused mission to land a role at Amazon, Meta, Microsoft, and other top tech companies in 6 months

This repository reflects consistent learning, growth, and real-world problem-solving as I prepare for interviews and technical evaluations. If you're also preparing for a data engineering role, I hope this inspires and helps you.

